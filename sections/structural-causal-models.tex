\documentclass[../main.tex]{subfiles}
\begin{document}
Classically, causality is studied using structural causal models introduced by \cite{pearl2000causality}. In the following section, we recap useful concepts and provide a few examples, primarily taken form \cite{elements_causal_inf} and \cite{Jonas_Peters_mini}. 
\subsection{Causal graphical models}
A \emph{causal graphical model} (sometimes referred to as a causal Bayesian network) is a pair that consists of a graph whose vertices correspond to the random variables in the system of interest and a compatible joint distriubtion on the variable. In order to characterize compatibablity, we need to connect probability theoretic independence to a graph theoretic notion. We first recall some definitions.  
\begin{defn}[Graph theoretic notions\cite{elements_causal_inf}6.1]\label{defn:Immorality}
    Let ${G=(V,E)}$ be a directed graph.

    A node ${X}$ is called a \emph{parent} of a node ${Y}$ if ${X\to Y\in E}$. We denote by ${\text{PA}(X)}$ the set of parents of ${X}$. 

    We say ${G}$ is \emph{acyclic} if there is no pair of distinct vertices ${(X,Y)}$ with paths ${\gamma_1: X\to \dots\to Y}$ and ${\gamma_1: Y\to \dots\to X}$. 

    An \emph{immorality} in a graph ${G}$ is a triple of nodes \\${(X,Y,Z)}$ of the graph such that ${\{(X,Z),(Y,Z)\}\subset E}$ as depicted in \autoref{fig:immorality-v-struc-nodes}
    \begin{figure}
            \[\begin{tikzcd}
            X && Y \\
            & Z
            \arrow[from=1-1, to=2-2]
            \arrow[from=1-3, to=2-2]
        \end{tikzcd}\]
        \caption{An immorality or V-structured nodes}
        \label{fig:immorality-v-struc-nodes}
        \end{figure} 
    \end{defn}
    \begin{defn}[d-separation\cite{elements_causal_inf} Def 6.1]\label{defn:d-separation}
    We say that two nodes on a graph ${X_i}$ and ${X_j}$ are d-separated by a collection of nodes ${S}$ if all undirected paths between ${X_i}$ and ${X_j}$ are blocked by ${S}$, i.e.
    \begin{enumerate}
        \item a path of the form path ${X_i \dots \rightarrow s \rightarrow \dots  X_j}$ contains a node ${s\in S}$ 
        \item a path of the form path ${X_i\dots \leftarrow s \rightarrow \dots \rightarrow X_j}$ contains a node ${s\in S}$ 
        \item a path of the form  ${X_i\dots \rightarrow s \leftarrow \dots \rightarrow X_j}$ \emph{does not} contain a node ${s\in S}$.  
    \end{enumerate}
    We say that two disjoint sets of nodes ${A}$ and ${B}$ are ${d}$-separated by ${S}$ if every pair of nodes ${(a,b)\in A\times B}$ is ${d}$-separated by ${S}$.       
    \end{defn}
    \begin{ex}[d-separation]\label{ex:d-separation}
    Consider the following graph $G$ 
    \[\begin{tikzcd}
        & {X_4} && {X_3} \\
        \\
        & {X_3} \\
        {X_2} \\
        & {X_1}
        \arrow[from=1-2, to=1-4]
        \arrow[from=1-2, to=3-2]
        \arrow[from=3-2, to=5-2]
        \arrow[from=4-1, to=5-2]
        \arrow[from=5-2, to=1-4]
    \end{tikzcd}\]
    The nodes ${X_2}$ and ${X_5}$ are d-separated by ${\{X_1,X_4\}}$, with ${X_2\to X_1\to X_5}$ being due to rule ${1}$ while ${X_2\to X_1\leftarrow X_3\leftarrow X_4\to X_5}$ due to rule ${2}$. 
    
    The nodes ${X_4}$ and ${X_1}$ is d-separated by ${X_3}$, with ${X_4\to X_3\to X_1}$ due to rule ${1}$ and ${X_5}$ being excluded due to rule ${3}$. 
    
    ${X_2}$ and ${X_4}$ are separated by ${\emptyset}$ with ${X_1}$ and ${X_5}$ being excluded due to rule ${3}$.   
    \end{ex}
    
    We now connect the graphical notion of d-separation to a probability distribution. 
    
    \begin{defn}[Markov property \cite{elements_causal_inf} Def 6.21]
    \label{defn:Markov-property}
    Given a DAG $G$ and a joint distribution $\mathbb{P}_V$ on the random variables corresponding to the nodes of $G$, this distribution is said to satisfy

    \begin{enumerate}
        \item the \emph{global Markov property} with respect to the DAG $G$ if
        \[
        A \perp\!\!\!\perp_G B \mid C \implies A \perp\!\!\!\perp B \mid C
        \]
        for all disjoint vertex sets $A$, $B$, $C$ (the symbol $\perp\!\!\!\perp_G$ denotes $d$-separation),
        
        \item the \emph{local Markov property} with respect to the DAG $G$ if each variable is independent of its non-descendants given its parents, and
        
        \item the \emph{Markov factorization property} with respect to the DAG $G$ if
        \[
        p(x) = p(x_1, \ldots, x_d) = \prod_{j=1}^{d} p(x_j \mid \text{pa}_j^G).
        \]
    \end{enumerate}
    For this last property, we have to assume that $\mathbb{P}_V$ has a density $p$; the factors in the product are referred to as \emph{causal Markov kernels} describing the conditional distributions $\mathbb{P}_{X_j \mid \text{PA}_j^G}$.
    \end{defn}
    \begin{thm}[Equivalence of Markov properties \cite{elements_causal_inf} Theorem 6.22]
    \label{thm:markov-equivalence}
        If $P_V$ has a density $p$, then all Markov properties in \autoref{defn:Markov-property} are equivalent.
    \end{thm}
    Using Markov equivalence as our notion of compatibablity, we are now ready to define a causal graphical model. 
    \begin{defn}[Causal graphical model \cite{elements_causal_inf} Def 6.32]
    \label{defn:Causal-graphical-model}
        A \emph{causal graphical model} over random variables ${\mathbf{X} = X_1,\dots, X_d}$ consists of a graph with one vertex for each random variable and a distribution ${\mathbb{P}_\mathbf{X}}$ such that ${\mathbb{P}_\mathbf{X}}$ has a strictly positive density function ${p}$ and is Markovian with respect to ${G}$. 
    \end{defn}
    As mentioned earlier, causal graphical models are sufficient to answer questions about interventions. 
    \begin{defn}[Interventional distributions \cite{elements_causal_inf} Eqn 6.8]
    \label{defn:Interventional-distributions}
        Let ${(G, \mathbb{P}_\mathbf{X})}$ be a causal graphical model and ${X_i\in \mathbb{X}}$ be an arbitrary variable and suppose we intervene by setting ${X_k = q(- | \tilde{\text{PA}}_{X_k})}$, where $\tilde{\text{PA}}_{X_k}$ represent a new set of parents that do not cause a directed cycle, and ${q}$ is a probability measure. The interventional distribution is 
        \begin{align*}
            \mathbb{P}^{\text{do}(X_k = q(- | \tilde{\text{PA}}_{X_k}))}(x_1,\dots, x_d) = \prod_{j\neq k} p(x_j, \text{pa}_{x_j}^G)q(- | \tilde{\text{pa}}_{x_k})
        \end{align*}
    \end{defn}
    Intuitively, the intervention ${\text{do}(X_k = q(- | \tilde{\text{PA}}_{X_k}))}$ makes ${\tilde{\text{PA}}_{X_k}}$ the parents of ${X_k}$, i.e. we edit the graph ${G}$ to make these variables parents of ${X_k}$ and places the probability measure ${q}$ on the variable.
    \begin{rem}[Hard Interventions]
    \label{rem:Hard-Interventions}
        The intervention we defined above is the most general kind of intervention often called a \emph{soft intervention}. Often, we are interested in hard interventions, which involve placing a point mass on ${X_k}$. In this case we get 
        \begin{align*}
            \mathbb{P}^{\text{do}(X_k = \delta_a(-))}(x_1,\dots, x_d) &= \prod_{j\neq k} p(x_j, \text{pa}_{x_j}^G)\delta_a(x_k)\\
            &= \begin{cases}
                \prod_{j\neq k} p(x_j, \text{pa}_{x_j}^G) & x_k = a \\
                0 & \text{otherwise}. 
            \end{cases}
        \end{align*}
        Note that in this case ${\tilde{\text{PA}}_{X_k}=\emptyset}$. In graphical terms, we delete all incoming edges to ${X_k}$. We often surpress the ${\delta}$ when denoting a hard intervention by writing $\mathbb{P}^{\text{do}(X_k = a)}(x_1,\dots, x_d)$.
    \end{rem}
    While graphical models are sufficient to compute interventional distributions, they are not sufficient to compute counterfactuals. Below is an example of a graphical model being used to compute interventional distributinos but failing to compute counterfactuals.
    \begin{ex}[Graphical model interventions and Counterfactuals]
    \label{ex:Graphical-model-interventions-and-Counterfactuals}
        TODO
    \end{ex}
    \begin{rem}[Computing interventions in practice]
    \label{rem:Computing-interventions-in-practice}
        Note that while the equation presented in \autoref{defn:Interventional-distributions} allows us to compute interventional distributions, it is often not the most practical for multiple reasons that we will not go into here. To address this the rules of do-calculus were developed, we refer the reader to \cite{elements_causal_inf} for the details. 
    \end{rem}
    \subsection{Structural causal models}   
    Structural causal models restrict the relationships between variables further by making each variable a function of its parents and some exogenous noise. In other words, each variable is a deterministic function of its parents and exogenous noise. This is in contrast to the graphical models we explored above, where each variable is a stochastic function of its parents. 
    \begin{defn}[Structural causal models]
    \label{defn:Structural-causal-models}
        
    \end{defn}
    Observe that SCMs are causal graphical models and can compute interventions in a similar manner. 
    We can now leverage the fact that the graph $G$ induced by an SCM is acyclic and define each variable as a function of its \emph{ancestors}.
    \begin{defn}[Ancestors]\label{defn:SCM-Ancestors}
        Let ${G}$ be the DAG induced by an SCM ${\mathfrak{C}}$ over the variables ${X_1,\dots, X_n}$. Then ${X_i}$ is an \emph{ancestor} of ${X_j}$ ${i\neq j}$ if there exists a directed path ${\gamma: X_i \rightarrow \dots \rightarrow X_j}$ in ${G}$. We denote the set of ancestors of ${X_j}$ by ${AN_j}$.       
    \end{defn}
    \begin{pro}[Ancestral sampling and observational distributions \cite{elements_causal_inf} (Proposition 6.3)]\label{pro:Ancestral sampling and observational distributions}
        Let ${\mathfrak{C} = (\mathbf{S}, \mathbb{P}_N)}$ be an SCM over the variables ${X_1,\dots, X_n}$. Then, there exists a unique joint probability distribution ${\mathbb{P}_X^\mathfrak{C}}$ over ${X_1,\dots , X_n}$ such that ${X_j = f_j(PA_j, N_j)}$ almost surely for all ${1\leq j \leq d}$.   
    \end{pro}
    \begin{proof}
        Since the induced graph ${G}$ is acyclic, we can express any ${X_j}$ as a function of the noise variables of its ancestors 
        \begin{align*}
        X_j  = g_j((N_k)_{k\in AN_j}).
        \end{align*}
        We obtain ${g_j}$ by recursively evaluating the variables in the structural equation ${X_j = f_j(PA_j, N_j)}$, i.e. replacing each ${X_i\in PA_j}$ with its structural equation ${f_i(PA_i, N_i)}$ and repeating the process until we reach a root node (a node in the graph with no parents). This process is well-defined since the graph is acyclic. By construction, we have ${X_j = f_j(PA_j, N_j)}$ almost surely since we sample any noise variables from the distribution ${\mathbb{P}_N}$ and manipulate them according to the structural equations.       
    \end{proof}

    \subsection{Causal effects}
     Let ${X, Y}$ be variables in an SCM ${\mathfrak{C}}$. What does it mean for ${X}$ to have a \emph{causal effect} on ${Y}$? This is not as straightforward as it might first seem. Indeed, \autoref{ex:Dormant-causal-effects} shows that merely having a directed path between ${X}$ and ${Y}$ does not imply that ${X}$ has a causal effect on ${Y}$.
     \begin{ex}[Dormant causal effects]
     \label{ex:Dormant-causal-effects}
        Consider the SCM ${\mathfrak{C}}$ on ${X, Y, W, Z}$ defined by the following structural equations
        \begin{align*}
        X &= N_X,\\
        W &= 2X + N_W,\\
        Z &= 3X + N_Z,\\
        Y &= -6W + 4Z +N_Y
        \end{align*}
        whose DAG is depicted in \autoref{fig:dag-dormant-causal-effects}.
        \begin{figure}
            \[\begin{tikzcd}
                & X \\
                W && Z \\
                & Y
                \arrow[from=1-2, to=2-1]
                \arrow[from=1-2, to=2-3]
                \arrow[from=2-1, to=3-2]
                \arrow[from=2-3, to=3-2]
            \end{tikzcd}\]
            \caption{DAG for the SCM in \autoref{ex:Dormant-causal-effects}.}
            \label{fig:dag-dormant-causal-effects}
        \end{figure}
        Intervening on ${X}$ has no effect on ${Y}$ since the two paths cancel each other out. 
        \begin{align*}
            \mathbb{P}^{\mathfrak{C}; \text{do}(X=x)}(Y=y)&= \mathbb{P}_N(-6(2x+N_W)+4(3x+N_Z)+N_Y=y)\\
            &= \mathbb{P}_N( -12x + 12x + N_Y-6N_w+4N_Z=y)= \mathbb{P}_N(N_Y-6N_w+4N_Z=y)\\
            &= \mathbb{P}^{\mathfrak{C}}(Y=y).
        \end{align*}
        In other words, intervening on ${X}$ does not change the distribution of ${Y}$. We will later see that this is an example of a \emph{dormant causal effect}, i.e. an effect that can be made active by intervening (in this case by intervening on ${W}$ or ${Z}$ which removes one of the paths). This is distinct from the case where there are no directed paths from ${X}$ to ${Y}$, in which case there is no causal effect at all. There is no intervention that can make ${X}$ effect $Y$ causally in this case.
     \end{ex}
     \begin{defn}[Total causal effect \cite{elements_causal_inf} (Proposition 6.13)]
     \label{defn:Total-causal-effect}
        Given a causal graphical model ${\mathfrak{C} = (G, \mathbb{P}_\mathbf{X})}$, there is a \emph{total causal effect} from ${X}$ to ${Y}$ if one of the following equivalent conditions hold:
        \begin{enumerate}
            \item ${X\not\perp Y}$ in ${\mathbb{P}^{\mathfrak{C};\text{do}(X=\tilde{N}_X)}}$ for some random variable ${\tilde{N}_X}$.
            \item There is ${x_0}$ such that ${\mathbb{P}^{\mathfrak{C};\text{do}(X=x_0)}_Y\neq \mathbb{P}_Y^\mathfrak{C}}$. In other words, there exists an intervention on ${X}$ that changes the distribution of ${Y}$.
            \item There exist ${x_0}$ and ${x_1}$ such that ${\mathbb{P}^{\mathfrak{C};\text{do}(X=x_0)}_Y\neq \mathbb{P}^{\mathfrak{C};\text{do}(X=x_1)}_Y }$. 
        \end{enumerate}
     \end{defn}
     As alluded to in \autoref{ex:Dormant-causal-effects}, the existence of a total causal effect is tied to the existence of a directed path. 
     \begin{pro}[Directed paths and total causal effects \cite{elements_causal_inf} (Proposition 6.14)]
     \label{pro:ro:Directed-paths-and-total-causal-effect}
        Let ${G}$ be the underlying DAG of an SCM ${\mathfrak{C}}$ and ${X,Y}$ be variables. If there is a total causal effect between ${X}$ and ${Y}$, then there exists a directed path ${X\to Y}$. The converse does not hold, i.e. there may be a directed path between ${X}$ and ${Y}$ without a corresponding total causal effect between the variables.
     \end{pro}
\end{document}