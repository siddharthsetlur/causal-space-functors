\documentclass[../main.tex]{subfiles}
\begin{document}
   Problems that require \emph{causal reasoning} occur naturally across numerous domains; for instance, a clinician might be interested in understanding the effect of a particular treatment on a patient presenting a certain condition, a central banker might be interested in the effect that lowering interest rates has on inflation, or a computer scientist might be interested in the effect that tuning certain weights of a neural network has on the outputs of the network. \emph{Causal models} including \emph{causal Bayesian nets (CBNs)}\cite{pearl1988probabilistic} and \emph{structural causal models (SCMs)} \cite{pearl2000causality} were first proposed by Pearl and others in an attempt to address these questions in a rigorous mathematical framework. Since then, there have been attempts at reformulating these causal models using: (1) string diagrams and category theory by Fong \cite{fong2013causal}, Fritz \cite{fritz_d-separation_2023}, Jacobs \cite{bojanczyk_causal_2019} and others; (2) a measure theoretic axiomatization by Park et al \cite{axioms-1}, \cite{axioms-2}. In this work, we show how each of these frameworks is related to the others and introduce a new categorical framework that is inspired by both the measure theoretic framework and the string diagrammatic framework. 
   \subsection{The ladder of causation}
   Causal reasoning as wse phrased above is extremely broad and there are different problems in causal reasoning of varying difficulty. Pearl introduced a heirarchy of increasingly difficult problems that a causal model might attempt to address called a \emph{causal ladder}\cite{pearl2000causality}. Suppose we have a collection ${V}$ of random variables, each rung of the causal lader attempts to answer a particular kind of question about the system $V$. Importantly, if a causal model is able to answer questions on a particular rung, it is automatically able to answer all questions on lower rungs. 
   \begin{enumerate}
      \item \textbf{Association}. Problems on this level can be answered if we know the joint distribution of the variables in ${V}$. Questions are typically of the form \emph{How would seeing ${X}$ change by belief in ${Y}$?}. 
      \item \textbf{Intervention}. On this level, we are interested in how the system behaves if we alter the system in a particular manner such as \emph{What would the distribution on $Y$ look like if I fix $X$ to be a certain value?}. Questions of this form are cannot be answered with just the observational distribution. Note that interventional questions subsume association questions, we could intervene by doing nothing and recover all questions on the previous rung. We will see that a \emph{causal structure} (often in the form of a graph) and a compatible observational distribution is sufficient to answer questions of this form. 
      \item \textbf{Counterfactuals}. Here we ask questions of the form: \emph{Given that I observed ${Z}$ to be particular value, what would the distribution on ${Y}$ look like if I fixed ${X}$ to be particular value?} these are particularly hard questions to answer because we are trying to answer questions about a hypothetical world in which we carried out the intervention on ${X}$ given observations of ${Z}$ in the ``real'' world where we did not carry out this intervention. Observe that by setting ${Z=\emptyset}$, we recover questions on the previous rung. Observational distributions with compatible causal structures are not sufficient to answer questions on this rung, we need some sort of determinism that encodes the precise relationship between variables, this information is often encoded in \emph{structural equations}. 
   \end{enumerate}
   The three rungs are better understood using an example. Consider a three variable system ${V}$ with binary variables ${R}$ (street wet on a given day), $S$ (sprinkler on or off on a given day), and $W$ (grass wet or dry on a given day). On the first rung, we could ask questions like what is the probability that the grass is wet given that the street is wet? We could answer this by simply computing ${\mathbb{P}(W=1|R=1)}$. We might imagine that the street being wet and the grass being wet are dependent on each other, e.g. if it rains then both will be wet, this is captured by the conditionals. 

   On the second rung, we might ask \emph{What is the probability that the grass is wet if I turn the sprinkler on?} We write this as ${\mathbb{P}(W=1|do(S=1))}$. In order to compute this it is not sufficient to know the joint distribution, we need to know that turning the sprinkler on \emph{causes} the grass to be wet and hence ${\mathbb{P}(W=1|do(S=1))\neq \mathbb{P}(W=1)}$.  Conversely, making the street wet, e.g. by hosing down the street, does not make the grass wet despite the fact that the fact that the two variables are dependent, i.e ${\mathbb{P}(W=1|do(R=1))=\mathbb{P}(W=1)}$.
   
   On the counterfactual level, we might ask \emph{Given that the street is wet, what is the probability that the grass would also have been wet if I had turned my sprinklers off, i.e. what is ${P(W=1|R=1;do(X=0))}$?}. Observe that here simply knowing that the sprinkler being on causes the grass to be wet and that the street being wet does not imply the grass beign wet is not sufficient. 
\end{document}